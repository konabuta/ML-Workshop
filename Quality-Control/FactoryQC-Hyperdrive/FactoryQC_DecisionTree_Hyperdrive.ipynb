{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 決定木モデルの自動パラメータチューニング\n",
    "Azure Machine Learning service が提供する自動ハイパーパラメータチューニング機能 **Hyperdrive** を利用して、Scikit-learn による決定木のハイパーパラメータチューニングを実施します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure ML Workspaceへ接続\n",
    "Azure Machine Learning service ワークスペースへ接続します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: azureml\n",
      "Azure region: eastus\n",
      "Subscription id: 9c0f91b8-eb2f-484c-979c-15848c098a6b\n",
      "Resource group: mlservice\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Experiment\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
    "\n",
    "experiment = Experiment(workspace = ws, name = \"simple-hyperdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.0.55\n"
     ]
    }
   ],
   "source": [
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## クラウドにデータをアップロード\n",
    "学習で使用するデータをオンプレミスからクラウドにアップロードします。ここではデフォルトの [Datastore](https://docs.microsoft.com/ja-JP/azure/machine-learning/service/how-to-access-data) \"workspaceblobstore\" を利用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datastoreの一覧\n",
    "#ws.datastores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'workspaceblobstore'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# デフォルトの Datastore を設定\n",
    "ds = ws.get_default_datastore()\n",
    "ds.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading ./data/Factory.csv\n",
      "Uploaded ./data/Factory.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_53ac5041af354195abdd688ab7d4c07b"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataフォルダにアップロード\n",
    "ds.upload(src_dir='./data', target_path='data', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習コード準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "project_folder = \"./script\"\n",
    "os.makedirs(project_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./script/myenv.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile {project_folder}/myenv.yml\n",
    "name: project_environment\n",
    "dependencies:\n",
    "- python=3.6.2\n",
    "- pip:\n",
    "  - azureml-defaults\n",
    "  - pydotplus\n",
    "- python-graphviz\n",
    "- scikit-learn=0.20.3\n",
    "channels:\n",
    "- conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./script/DecisionTree_hyperdrive.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {project_folder}/DecisionTree_hyperdrive.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from azureml.core import Run\n",
    "run = Run.get_context()\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Decision Tree Hyperparameter')\n",
    "parser.add_argument('--max_depth', '-m', type=int, default=5, help='max depth of Decision Tree')\n",
    "parser.add_argument('--criterion', '-c', type=str, default=\"gini\", help='Criterion policy')\n",
    "parser.add_argument('--min_samples_split', '-s', type=int, default=2, help='Min Sample Split')\n",
    "parser.add_argument('--dataset', '-d', dest='data_folder',help='The datastore')\n",
    "\n",
    "args = parser.parse_args()\n",
    "np.random.seed(12345)\n",
    "\n",
    "# データ準備\n",
    "df = pd.read_csv(args.data_folder+\"/data/Factory.csv\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop([\"Quality\",\"ID\"],axis=1)\n",
    "y = df[\"Quality\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1,random_state=100,stratify=y)\n",
    "\n",
    "# アルゴリズム\n",
    "from sklearn import tree\n",
    "max_depth = args.max_depth\n",
    "criterion = args.criterion\n",
    "min_samples_split = args.min_samples_split\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_depth=max_depth, criterion=criterion, min_samples_split = min_samples_split)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 精度確認\n",
    "from sklearn.metrics import (roc_curve, auc, accuracy_score)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "print(\"Accuracy\", accuracy_score(pred, y_test))\n",
    "\n",
    "run.log(\"Accuracy\",accuracy_score(pred, y_test))\n",
    "run.log(\"Max Depth\",max_depth)\n",
    "run.log(\"criterion\",criterion)\n",
    "run.log(\"Min Samples Split\",min_samples_split)\n",
    "\n",
    "import pickle\n",
    "filename = 'DT-model.pkl'\n",
    "pickle.dump(clf, open(filename, 'wb'))\n",
    "run.upload_file(name= \"outputs/\"+filename, path_or_stream=filename)\n",
    "\n",
    "print(clf.predict(X_test))\n",
    "print(clf.predict_proba(X_test))\n",
    "\n",
    "# # Model  Picture\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "with run:\n",
    "    dot_data = tree.export_graphviz(clf, out_file=None, feature_names=X.columns, proportion=True, filled=True, rounded=True, special_characters=True)  \n",
    "    graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "    graph.write_png(\"outputs/tree.png\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Compute設定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning Computeの設定を行います。既存の Machine Learning Compute の環境は、Azure Portal のコンピューティングのタブもしくは、下記コマンドで確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "compute_target = ComputeTarget(ws,\"cpucluster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル学習設定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimatorの設定を行います。今回は Scikit-learn による機械学習モデリングのため、[Scikit-learn Estimator](https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.sklearn.sklearn?view=azure-ml-py) を利用します。最初はハイパーパラメータを指定した状態で実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.train.dnn import TensorFlow\n",
    "\n",
    "script_params = {\n",
    "    '--dataset': ds.as_mount(),\n",
    "    '--max_dept':5,\n",
    "    '--criterion':'gini',\n",
    "    '--min_samples_split':2\n",
    "}\n",
    "\n",
    "estimator = Estimator(source_directory=project_folder,\n",
    "                    compute_target=compute_target,\n",
    "                    entry_script='DecisionTree_hyperdrive.py',\n",
    "                    script_params=script_params,\n",
    "                    conda_dependencies_file=\"myenv.yml\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行開始"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記で定義した scikit-learn Estimator の設定に従って、トレーニング環境を構築し、モデル学習を始めます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: simple-hyperdrive,\n",
      "Id: simple-hyperdrive_1566738739_57033de4,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Queued)\n"
     ]
    }
   ],
   "source": [
    "run = experiment.submit(estimator)\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f275d8df40e24918a7180650f2071e6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Status を取りにいっているだけなので、何回実行しても問題なし\n",
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデル無事完了したことを確認して、次に進みます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル登録"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "['azureml-logs/55_azureml-execution-tvmps_4d4dc63877ac826916e303df8ae02674324475529018dee7a1051c875ffc5e43_p.txt', 'azureml-logs/65_job_prep-tvmps_4d4dc63877ac826916e303df8ae02674324475529018dee7a1051c875ffc5e43_p.txt', 'azureml-logs/70_driver_log.txt', 'azureml-logs/75_job_post-tvmps_4d4dc63877ac826916e303df8ae02674324475529018dee7a1051c875ffc5e43_p.txt', 'logs/azureml/130_azureml.log', 'logs/azureml/azureml.log', 'outputs/DT-model.pkl', 'outputs/tree.png']"
      ],
      "text/plain": [
       "['azureml-logs/55_azureml-execution-tvmps_4d4dc63877ac826916e303df8ae02674324475529018dee7a1051c875ffc5e43_p.txt',\n",
       " 'azureml-logs/65_job_prep-tvmps_4d4dc63877ac826916e303df8ae02674324475529018dee7a1051c875ffc5e43_p.txt',\n",
       " 'azureml-logs/70_driver_log.txt',\n",
       " 'azureml-logs/75_job_post-tvmps_4d4dc63877ac826916e303df8ae02674324475529018dee7a1051c875ffc5e43_p.txt',\n",
       " 'logs/azureml/130_azureml.log',\n",
       " 'logs/azureml/azureml.log',\n",
       " 'outputs/DT-model.pkl',\n",
       " 'outputs/tree.png']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run 完了後に実行\n",
    "run.get_file_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT-hyperdrive\tDT-hyperdrive:7\t7\n"
     ]
    }
   ],
   "source": [
    "model = run.register_model(model_name = 'DT-hyperdrive', model_path = 'outputs/DT-model.pkl',tags = {'area': \"decision tree model for quality prediciton with hyperdrive\", 'type': \"scikit-learn DT\"})\n",
    "print(model.name, model.id, model.version, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run.get_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ハイパーパラメータチューニング  Hyperdrive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning Compute を用いて複数サーバでパラメータチューニングを分散で実行します。今回は Random Search を用います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.parameter_expressions import choice\n",
    "    \n",
    "\n",
    "# ハイパーパラメータの範囲\n",
    "param_sampling = RandomParameterSampling( {\n",
    "    \"--max_dept\": choice(range(1,100)),\n",
    "    \"--criterion\": choice(\"gini\",\"entropy\"),\n",
    "    \"--min_samples_split\":choice(range(2,5))\n",
    "    }\n",
    ")\n",
    "\n",
    "hyperdrive_run_config = HyperDriveConfig(estimator=estimator,\n",
    "                                            hyperparameter_sampling=param_sampling, \n",
    "                                            primary_metric_name='Accuracy',\n",
    "                                            primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                                            max_total_runs=20,\n",
    "                                            max_concurrent_runs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実行開始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The same input parameter(s) are specified in estimator/run_config script params and HyperDrive parameter space. HyperDrive parameter space definition will override these duplicate entries. ['--max_dept', '--criterion', '--min_samples_split'] is the list of overridden parameter(s).\n"
     ]
    }
   ],
   "source": [
    "hyperdrive_run = experiment.submit(hyperdrive_run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6ae13f955d4e518e75ab282854f886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(hyperdrive_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Champion Model のダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = hyperdrive_run.get_best_run_by_primary_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = best_run.register_model(model_name='hyperdrive-model', model_path='outputs/DT-model.pkl')\n",
    "model = run.register_model(model_name='hyperdrive-model', model_path='outputs/DT-model.pkl')\n",
    "path = model.download(exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "fitted_model = joblib.load(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テストデータの取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./data/Factory.csv')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop([\"Quality\",\"ID\"],axis=1)\n",
    "y = df[\"Quality\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1,random_state=100,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル解釈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.explain.model.tabular_explainer import TabularExplainer\n",
    "classes = [\"false\",\"true\"]\n",
    "tabular_explainer = TabularExplainer(fitted_model, X_train, features=X_train.columns, classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_explanation = tabular_explainer.explain_global(X_test[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434596b98a5f41748636736a725af37a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExplanationWidget(value={'predictedY': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<azureml.contrib.explain.model.visualize.ExplanationDashboard.ExplanationDashboard at 0x125499cf8>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.contrib.explain.model.visualize import ExplanationDashboard\n",
    "ExplanationDashboard(global_explanation, fitted_model, X_test[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
